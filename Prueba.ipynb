{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dc0553",
   "metadata": {},
   "source": [
    "0) Parámetros globales (ruta + semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7d7f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\dataset_gua_crops\\cropped_images\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 0: CONFIG GLOBAL ===\n",
    "import os, random, numpy as np, torch\n",
    "BASE = r\"C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\dataset_gua_crops\\cropped_images\"\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); \n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"BASE:\", BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1b343",
   "metadata": {},
   "source": [
    "1) Organizar dataset (raíz → defectuosas / normales + labels.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6131458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset organizado.\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 1: ORGANIZAR DATASET ===\n",
    "import os, shutil, csv\n",
    "\n",
    "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".bmp\"}\n",
    "DEF_DIR  = os.path.join(BASE, \"defectuosas\")\n",
    "NORM_DIR = os.path.join(BASE, \"normales\")\n",
    "os.makedirs(DEF_DIR, exist_ok=True); os.makedirs(NORM_DIR, exist_ok=True)\n",
    "\n",
    "def find_image(base_dir, basename):\n",
    "    for ext in IMG_EXTS:\n",
    "        p = os.path.join(base_dir, basename + ext)\n",
    "        if os.path.exists(p): return p\n",
    "    return None\n",
    "\n",
    "# mover defectuosas usando .json\n",
    "json_files = [f for f in os.listdir(BASE) if f.lower().endswith(\".json\")]\n",
    "for jf in json_files:\n",
    "    base = os.path.splitext(jf)[0]\n",
    "    js = os.path.join(BASE, jf)\n",
    "    im = find_image(BASE, base)\n",
    "    shutil.move(js, os.path.join(DEF_DIR, jf))\n",
    "    if im: shutil.move(im, os.path.join(DEF_DIR, os.path.basename(im)))\n",
    "\n",
    "# mover lo demás (imágenes) a normales\n",
    "for f in list(os.listdir(BASE)):\n",
    "    p = os.path.join(BASE, f)\n",
    "    if os.path.isfile(p) and os.path.splitext(f)[1].lower() in IMG_EXTS:\n",
    "        shutil.move(p, os.path.join(NORM_DIR, f))\n",
    "\n",
    "# labels.csv\n",
    "with open(os.path.join(BASE, \"labels.csv\"), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"filename\",\"label\"])\n",
    "    for fimg in sorted(os.listdir(DEF_DIR)):\n",
    "        if os.path.splitext(fimg)[1].lower() in IMG_EXTS:\n",
    "            w.writerow([os.path.join(\"defectuosas\", fimg), 1])\n",
    "    for fimg in sorted(os.listdir(NORM_DIR)):\n",
    "        if os.path.splitext(fimg)[1].lower() in IMG_EXTS:\n",
    "            w.writerow([os.path.join(\"normales\", fimg), 0])\n",
    "\n",
    "print(\"✅ Dataset organizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df81bd",
   "metadata": {},
   "source": [
    "2) Crear splits: train (solo normales), val y test (mixtos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876a4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Splits listos.\n",
      "train: 109 normales / 0 defectuosas\n",
      "val: 23 normales + 18 defectuosas\n",
      "test: 24 normales + 27 defectuosas\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 2: SPLITS ===\n",
    "import os, shutil, csv, math, random\n",
    "SPLITS = os.path.join(BASE, \"splits\")\n",
    "for d in [\"train\",\"val\",\"test\"]:\n",
    "    os.makedirs(os.path.join(SPLITS, d, \"images\"), exist_ok=True)\n",
    "\n",
    "def list_imgs(folder):\n",
    "    return sorted([f for f in os.listdir(folder) if os.path.splitext(f)[1].lower() in IMG_EXTS])\n",
    "\n",
    "norm = list_imgs(NORM_DIR); defc = list_imgs(DEF_DIR)\n",
    "random.shuffle(norm); random.shuffle(defc)\n",
    "\n",
    "# normales 70/15/15\n",
    "n = len(norm)\n",
    "n_tr, n_val = math.floor(0.7*n), math.floor(0.15*n)\n",
    "norm_train = norm[:n_tr]\n",
    "norm_val   = norm[n_tr:n_tr+n_val]\n",
    "norm_test  = norm[n_tr+n_val:]\n",
    "\n",
    "# defectuosas 40% val / 60% test\n",
    "m = len(defc)\n",
    "m_val = math.floor(0.4*m)\n",
    "def_val  = defc[:m_val]\n",
    "def_test = defc[m_val:]\n",
    "\n",
    "def cp(files, src, split):\n",
    "    for fn in files:\n",
    "        shutil.copy2(os.path.join(src, fn), os.path.join(SPLITS, split, \"images\", fn))\n",
    "\n",
    "cp(norm_train, NORM_DIR, \"train\")\n",
    "cp(norm_val,   NORM_DIR, \"val\")\n",
    "cp(norm_test,  NORM_DIR, \"test\")\n",
    "cp(def_val,    DEF_DIR,  \"val\")\n",
    "cp(def_test,   DEF_DIR,  \"test\")\n",
    "\n",
    "def write_labels(split, normals, defects):\n",
    "    with open(os.path.join(SPLITS, split, \"labels.csv\"), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"filename\",\"label\"])\n",
    "        for fn in sorted(normals):  w.writerow([os.path.join(\"images\", fn), 0])\n",
    "        for fn in sorted(defects):  w.writerow([os.path.join(\"images\", fn), 1])\n",
    "\n",
    "write_labels(\"train\", norm_train, [])\n",
    "write_labels(\"val\",   norm_val,   def_val)\n",
    "write_labels(\"test\",  norm_test,  def_test)\n",
    "\n",
    "print(\"✅ Splits listos.\")\n",
    "print(\"train:\", len(norm_train), \"normales / 0 defectuosas\")\n",
    "print(\"val:\",   len(norm_val),   \"normales +\", len(def_val),  \"defectuosas\")\n",
    "print(\"test:\",  len(norm_test),  \"normales +\", len(def_test), \"defectuosas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8ce63",
   "metadata": {},
   "source": [
    "3) PatchCore – cargar extractor y funciones comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c3e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 3: PATCHCORE - EXTRACTOR Y UTILES ===\n",
    "import cv2, numpy as np, torch, torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm, trange\n",
    "import json, os\n",
    "\n",
    "IMG_SIZE = 256\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# extractor ResNet18 (capas intermedias)\n",
    "backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(DEVICE)\n",
    "backbone.eval()\n",
    "FE_LAYERS = [\"layer2\",\"layer3\"]\n",
    "\n",
    "class FeatHook:\n",
    "    def __init__(self, m): self.h = m.register_forward_hook(self.hook); self.feat=None\n",
    "    def hook(self, m, i, o): self.feat = o.detach()\n",
    "    def close(self): self.h.remove()\n",
    "\n",
    "hook2 = FeatHook(dict(backbone.named_modules())[\"layer2\"])\n",
    "hook3 = FeatHook(dict(backbone.named_modules())[\"layer3\"])\n",
    "\n",
    "def load_img(path, size=IMG_SIZE):\n",
    "    im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if im is None: raise FileNotFoundError(path)\n",
    "    im = cv2.resize(im, (size,size), interpolation=cv2.INTER_AREA)\n",
    "    x = im.astype(np.float32)/255.0\n",
    "    x = np.stack([x,x,x], axis=0)          # 3 canales\n",
    "    return torch.from_numpy(x).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def extract_concat_features(img_path):\n",
    "    x = load_img(img_path)\n",
    "    with torch.no_grad():\n",
    "        _ = backbone(x)\n",
    "    f2 = hook2.feat; f3 = hook3.feat\n",
    "    def up(x): \n",
    "        return torch.nn.functional.interpolate(x, size=f2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    f3u = up(f3)\n",
    "    fcat = torch.cat([f2, f3u], dim=1).squeeze(0)  # (C,H,W)\n",
    "    return fcat\n",
    "\n",
    "def patchify(fmap):  # (C,H,W) -> (N,C)\n",
    "    C,H,W = fmap.shape\n",
    "    return fmap.permute(1,2,0).reshape(H*W, C).contiguous()\n",
    "\n",
    "def read_csv(csv_path):\n",
    "    items=[]\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            rel,lbl = line.strip().split(\",\")\n",
    "            items.append((rel,int(lbl)))\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84169a",
   "metadata": {},
   "source": [
    "4) Construir Memory Bank (solo train normales) + CORESET y guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6396439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo parches de TRAIN (solo normales)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:01<00:00, 83.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco completo: (111616, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5579/5579 [03:20<00:00, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Memory bank guardado: (5580, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 4: MEMORY BANK + CORESET ===\n",
    "TRAIN_DIR = os.path.join(SPLITS, \"train\")\n",
    "PATCHCORE_DIR = os.path.join(BASE, \"patchcore\")\n",
    "os.makedirs(PATCHCORE_DIR, exist_ok=True)\n",
    "\n",
    "train_items = read_csv(os.path.join(TRAIN_DIR, \"labels.csv\"))\n",
    "train_imgs = [os.path.join(TRAIN_DIR, rel) for rel,lbl in train_items if lbl==0]\n",
    "\n",
    "all_patches=[]\n",
    "print(\"Extrayendo parches de TRAIN (solo normales)...\")\n",
    "for p in tqdm(train_imgs):\n",
    "    fcat = extract_concat_features(p)\n",
    "    patches = patchify(fcat)\n",
    "    patches = torch.nn.functional.normalize(patches, p=2, dim=1)\n",
    "    all_patches.append(patches.cpu().numpy())\n",
    "\n",
    "bank_full = np.vstack(all_patches).astype(np.float32)\n",
    "print(\"Banco completo:\", bank_full.shape)\n",
    "\n",
    "# CORESET simple por proyección aleatoria + k-center greedy\n",
    "def random_projection(X, out_dim=128, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    R = rng.standard_normal((X.shape[1], out_dim)).astype(np.float32)\n",
    "    Z = X @ R\n",
    "    Z /= (np.linalg.norm(Z, axis=1, keepdims=True)+1e-8)\n",
    "    return Z\n",
    "\n",
    "def kcenter_greedy(Z, m, seed=SEED):\n",
    "    rng = np.random.default_rng(seed); N = Z.shape[0]\n",
    "    start = int(rng.integers(0, N)); centers=[start]\n",
    "    d = np.linalg.norm(Z - Z[start], axis=1)\n",
    "    for _ in trange(1, m):\n",
    "        i = int(np.argmax(d)); centers.append(i)\n",
    "        d = np.minimum(d, np.linalg.norm(Z - Z[i], axis=1))\n",
    "    return np.array(centers, dtype=np.int64)\n",
    "\n",
    "CORESET_RATIO = 0.05\n",
    "m = max(1, int(CORESET_RATIO * bank_full.shape[0]))\n",
    "Z = random_projection(bank_full, out_dim=128)\n",
    "sel = kcenter_greedy(Z, m=m)\n",
    "bank = bank_full[sel]\n",
    "np.savez(os.path.join(PATCHCORE_DIR, \"memory_bank_core.npz\"),\n",
    "         bank=bank, img_size=np.array([IMG_SIZE], dtype=np.int32),\n",
    "         layers=np.array(FE_LAYERS, dtype=object))\n",
    "print(\"✅ Memory bank guardado:\", bank.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232f9f7",
   "metadata": {},
   "source": [
    "5) Validación: calibrar umbral y guardar config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89b7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:05<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL -> ROC-AUC=0.8865 | bestF1_thr=0.419504\n",
      "Umbral p95 normales: 0.356087\n",
      "✅ Umbral guardado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 5: VALIDACIÓN (calibrar umbral) ===\n",
    "VAL_DIR = os.path.join(SPLITS, \"val\")\n",
    "VAL_CSV = os.path.join(VAL_DIR, \"labels.csv\")\n",
    "items = read_csv(VAL_CSV)\n",
    "\n",
    "# cargar banco y preparar KNN\n",
    "mb = np.load(os.path.join(PATCHCORE_DIR, \"memory_bank_core.npz\"), allow_pickle=True)\n",
    "bank = mb[\"bank\"]  # (M, C)\n",
    "knn = NearestNeighbors(n_neighbors=3, algorithm=\"auto\").fit(bank)\n",
    "\n",
    "def anomaly_map_and_score(img_path):\n",
    "    fcat = extract_concat_features(img_path)\n",
    "    Hf,Wf = fcat.shape[-2:]\n",
    "    patches = patchify(fcat)\n",
    "    patches = torch.nn.functional.normalize(patches, p=2, dim=1).cpu().numpy()\n",
    "    dists,_ = knn.kneighbors(patches, return_distance=True)\n",
    "    patch_scores = dists.mean(axis=1).reshape(Hf,Wf).astype(np.float32)\n",
    "    score = float(patch_scores.max())\n",
    "    return score\n",
    "\n",
    "# obtener scores/labels\n",
    "y_true, s = [], []\n",
    "for rel,lbl in tqdm(items):\n",
    "    p = os.path.join(VAL_DIR, rel)\n",
    "    y_true.append(lbl)\n",
    "    s.append(anomaly_map_and_score(p))\n",
    "\n",
    "y_true = np.array(y_true); s = np.array(s)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "auc_roc = roc_auc_score(y_true, s)\n",
    "prec, rec, thr = precision_recall_curve(y_true, s)\n",
    "f1s = 2*prec*rec/(prec+rec+1e-8)\n",
    "best_idx = int(np.argmax(f1s))\n",
    "thr_f1 = float(thr[best_idx])\n",
    "print(f\"VAL -> ROC-AUC={auc_roc:.4f} | bestF1_thr={thr_f1:.6f}\")\n",
    "\n",
    "# percentil 95 de normales (robusto)\n",
    "thr_p95 = float(np.percentile(s[y_true==0], 95))\n",
    "print(\"Umbral p95 normales:\", round(thr_p95,6))\n",
    "\n",
    "# guardar config\n",
    "cfg = {\"threshold\": thr_p95}\n",
    "with open(os.path.join(PATCHCORE_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(cfg, f)\n",
    "print(\"✅ Umbral guardado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6179378",
   "metadata": {},
   "source": [
    "6) Test: métricas finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa70932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:03<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix [[TN FP],[FN TP]]:\n",
      " [[23  1]\n",
      " [ 3 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8846    0.9583    0.9200        24\n",
      "           1     0.9600    0.8889    0.9231        27\n",
      "\n",
      "    accuracy                         0.9216        51\n",
      "   macro avg     0.9223    0.9236    0.9215        51\n",
      "weighted avg     0.9245    0.9216    0.9216        51\n",
      "\n",
      "ROC-AUC (scores): 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 6: TEST (métricas finales) ===\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "TEST_DIR = os.path.join(SPLITS, \"test\")\n",
    "TEST_CSV = os.path.join(TEST_DIR, \"labels.csv\")\n",
    "cfg = json.load(open(os.path.join(PATCHCORE_DIR, \"config.json\"), \"r\"))\n",
    "thr = cfg[\"threshold\"]\n",
    "\n",
    "items = read_csv(TEST_CSV)\n",
    "y_true, s = [], []\n",
    "for rel,lbl in tqdm(items):\n",
    "    p = os.path.join(TEST_DIR, rel)\n",
    "    y_true.append(lbl)\n",
    "    s.append(anomaly_map_and_score(p))\n",
    "\n",
    "y_true = np.array(y_true); s = np.array(s)\n",
    "y_pred = (s > thr).astype(int)\n",
    "\n",
    "auc_roc = roc_auc_score(y_true, s)\n",
    "print(\"Confusion matrix [[TN FP],[FN TP]]:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(\"ROC-AUC (scores):\", round(auc_roc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be0c48",
   "metadata": {},
   "source": [
    "7) Visuales (overlay, heatmap, polígonos) para demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "510c5ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Visuales guardadas en: C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\dataset_gua_crops\\cropped_images\\patchcore\\viz\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 7: VISUALIZACIÓN ===\n",
    "viz_dir = os.path.join(PATCHCORE_DIR, \"viz\"); os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "def heat_and_polys(img_path, score_map, percent=98):\n",
    "    raw = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    heat = cv2.resize(score_map, (raw.shape[1], raw.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "    heat_norm = (heat - heat.min()) / (heat.max() - heat.min() + 1e-8)\n",
    "    heat_u8 = (heat_norm*255).astype(np.uint8)\n",
    "    heat_color = cv2.applyColorMap(heat_u8, cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(cv2.cvtColor(raw, cv2.COLOR_GRAY2BGR), 0.6, heat_color, 0.4, 0)\n",
    "\n",
    "    t = np.percentile(heat_u8, percent)\n",
    "    _, mask = cv2.threshold(heat_u8, t, 255, cv2.THRESH_BINARY)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8), 1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8), 1)\n",
    "    cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) < 25: continue\n",
    "        cv2.polylines(overlay, [c], True, (0,255,0), 2)\n",
    "    return overlay, heat_color, mask\n",
    "\n",
    "# demo en 8 imágenes de test\n",
    "for rel,_ in items[:8]:\n",
    "    p = os.path.join(TEST_DIR, rel)\n",
    "    fcat = extract_concat_features(p)\n",
    "    Hf,Wf = fcat.shape[-2:]\n",
    "    patches = patchify(fcat)\n",
    "    patches = torch.nn.functional.normalize(patches, p=2, dim=1).cpu().numpy()\n",
    "    dists,_ = knn.kneighbors(patches, return_distance=True)\n",
    "    patch_scores = dists.mean(axis=1).reshape(Hf,Wf).astype(np.float32)\n",
    "\n",
    "    ov, heat_c, mask = heat_and_polys(p, patch_scores, percent=98)\n",
    "    base = os.path.splitext(os.path.basename(p))[0]\n",
    "    cv2.imwrite(os.path.join(viz_dir,f\"{base}_overlay.png\"), ov)\n",
    "    cv2.imwrite(os.path.join(viz_dir,f\"{base}_heat.png\"), heat_c)\n",
    "    cv2.imwrite(os.path.join(viz_dir,f\"{base}_mask.png\"), mask)\n",
    "\n",
    "print(\"✅ Visuales guardadas en:\", viz_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
