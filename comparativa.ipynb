{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241a377f",
   "metadata": {},
   "source": [
    "Celda 0 â€” Config global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2090cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\comparacion\\dataset_gua_crops\\cropped_images\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 0: CONFIG GLOBAL ===\n",
    "import os, random, numpy as np, torch\n",
    "\n",
    "BASE = r\"C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\comparacion\\dataset_gua_crops\\cropped_images\"\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46781d50",
   "metadata": {},
   "source": [
    "ðŸ”¹ Celda 1 â€” Organizar dataset (raÃ­z â†’ defectuosas/normales + labels.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0bd42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset organizado en C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\comparacion\\dataset_gua_crops\\cropped_images\n",
      " - defectuosas: 45\n",
      " - normales   : 156\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 1: ORGANIZAR DATASET ===\n",
    "import os, shutil, csv\n",
    "\n",
    "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".bmp\"}\n",
    "DEF_DIR  = os.path.join(BASE, \"defectuosas\")\n",
    "NORM_DIR = os.path.join(BASE, \"normales\")\n",
    "os.makedirs(DEF_DIR, exist_ok=True); os.makedirs(NORM_DIR, exist_ok=True)\n",
    "\n",
    "def find_image(base_dir, basename):\n",
    "    for ext in IMG_EXTS:\n",
    "        p = os.path.join(base_dir, basename + ext)\n",
    "        if os.path.exists(p): return p\n",
    "    return None\n",
    "\n",
    "# mover defectuosas usando .json\n",
    "json_files = [f for f in os.listdir(BASE) if f.lower().endswith(\".json\")]\n",
    "for jf in json_files:\n",
    "    base = os.path.splitext(jf)[0]\n",
    "    js = os.path.join(BASE, jf)\n",
    "    im = find_image(BASE, base)\n",
    "    shutil.move(js, os.path.join(DEF_DIR, jf))\n",
    "    if im and os.path.exists(im):\n",
    "        shutil.move(im, os.path.join(DEF_DIR, os.path.basename(im)))\n",
    "\n",
    "# mover lo demÃ¡s (imÃ¡genes) a normales\n",
    "for f in list(os.listdir(BASE)):\n",
    "    p = os.path.join(BASE, f)\n",
    "    if os.path.isfile(p) and os.path.splitext(f)[1].lower() in IMG_EXTS:\n",
    "        shutil.move(p, os.path.join(NORM_DIR, f))\n",
    "\n",
    "# labels.csv\n",
    "with open(os.path.join(BASE, \"labels.csv\"), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f); w.writerow([\"filename\",\"label\"])\n",
    "    for fimg in sorted(os.listdir(DEF_DIR)):\n",
    "        if os.path.splitext(fimg)[1].lower() in IMG_EXTS:\n",
    "            w.writerow([os.path.join(\"defectuosas\", fimg), 1])\n",
    "    for fimg in sorted(os.listdir(NORM_DIR)):\n",
    "        if os.path.splitext(fimg)[1].lower() in IMG_EXTS:\n",
    "            w.writerow([os.path.join(\"normales\", fimg), 0])\n",
    "\n",
    "print(\"âœ… Dataset organizado en\", BASE)\n",
    "print(\" - defectuosas:\", len([x for x in os.listdir(DEF_DIR) if os.path.splitext(x)[1].lower() in IMG_EXTS]))\n",
    "print(\" - normales   :\", len([x for x in os.listdir(NORM_DIR) if os.path.splitext(x)[1].lower() in IMG_EXTS]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5b176",
   "metadata": {},
   "source": [
    "Celda 2 â€” Crear splits (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4d5d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Splits listos en C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\comparacion\\dataset_gua_crops\\cropped_images\\splits\n",
      "train: normales= 109 , defectuosas=0\n",
      "val  : normales= 23 , defectuosas= 18\n",
      "test : normales= 24 , defectuosas= 27\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 2: SPLITS ===\n",
    "import os, shutil, csv, math, random\n",
    "\n",
    "SPLITS = os.path.join(BASE, \"splits\")\n",
    "for d in [\"train\",\"val\",\"test\"]:\n",
    "    os.makedirs(os.path.join(SPLITS, d, \"images\"), exist_ok=True)\n",
    "\n",
    "def list_imgs(folder, exts={\".png\",\".jpg\",\".jpeg\",\".bmp\"}):\n",
    "    return sorted([f for f in os.listdir(folder) if os.path.splitext(f)[1].lower() in exts])\n",
    "\n",
    "norm = list_imgs(os.path.join(BASE,\"normales\"))\n",
    "defc = list_imgs(os.path.join(BASE,\"defectuosas\"))\n",
    "random.shuffle(norm); random.shuffle(defc)\n",
    "\n",
    "# normales 70/15/15\n",
    "n = len(norm)\n",
    "n_tr, n_val = math.floor(0.7*n), math.floor(0.15*n)\n",
    "norm_train = norm[:n_tr]\n",
    "norm_val   = norm[n_tr:n_tr+n_val]\n",
    "norm_test  = norm[n_tr+n_val:]\n",
    "\n",
    "# defectuosas 40% val / 60% test (ninguna en train)\n",
    "m = len(defc)\n",
    "m_val = math.floor(0.4*m)\n",
    "def_val  = defc[:m_val]\n",
    "def_test = defc[m_val:]\n",
    "\n",
    "def cp(files, src, split):\n",
    "    for fn in files:\n",
    "        shutil.copy2(os.path.join(src, fn), os.path.join(SPLITS, split, \"images\", fn))\n",
    "\n",
    "cp(norm_train, os.path.join(BASE,\"normales\"), \"train\")\n",
    "cp(norm_val,   os.path.join(BASE,\"normales\"), \"val\")\n",
    "cp(norm_test,  os.path.join(BASE,\"normales\"), \"test\")\n",
    "cp(def_val,    os.path.join(BASE,\"defectuosas\"), \"val\")\n",
    "cp(def_test,   os.path.join(BASE,\"defectuosas\"), \"test\")\n",
    "\n",
    "def write_labels(split, normals, defects):\n",
    "    with open(os.path.join(SPLITS, split, \"labels.csv\"), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"filename\",\"label\"])\n",
    "        for fn in sorted(normals): w.writerow([os.path.join(\"images\", fn), 0])\n",
    "        for fn in sorted(defects): w.writerow([os.path.join(\"images\", fn), 1])\n",
    "\n",
    "write_labels(\"train\", norm_train, [])\n",
    "write_labels(\"val\",   norm_val,   def_val)\n",
    "write_labels(\"test\",  norm_test,  def_test)\n",
    "\n",
    "print(\"âœ… Splits listos en\", SPLITS)\n",
    "print(\"train: normales=\",len(norm_train),\", defectuosas=0\")\n",
    "print(\"val  : normales=\",len(norm_val),  \", defectuosas=\",len(def_val))\n",
    "print(\"test : normales=\",len(norm_test), \", defectuosas=\",len(def_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac89c84",
   "metadata": {},
   "source": [
    "Celda 3 â€” Autoencoder (entrenar + calibrar umbral en val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5ff5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train imgs (solo normales): 109 | Val imgs (mixto): 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:108: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=='cuda'))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] loss=0.13966 | val_auc=0.3792 | bestF1=0.6102 | thr*=0.268923 | lr=0.00200 | *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002] loss=0.10023 | val_auc=0.6473 | bestF1=0.7059 | thr*=0.277596 | lr=0.00200 | *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[003] loss=0.06759 | val_auc=0.6232 | bestF1=0.6800 | thr*=0.199250 | lr=0.00200 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004] loss=0.04880 | val_auc=0.6377 | bestF1=0.7059 | thr*=0.168432 | lr=0.00199 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[005] loss=0.03800 | val_auc=0.6280 | bestF1=0.6923 | thr*=0.150034 | lr=0.00199 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[006] loss=0.02462 | val_auc=0.7512 | bestF1=0.7442 | thr*=0.128503 | lr=0.00198 | *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[007] loss=0.01748 | val_auc=0.6618 | bestF1=0.6800 | thr*=0.109183 | lr=0.00198 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[008] loss=0.01546 | val_auc=0.6232 | bestF1=0.6667 | thr*=0.108263 | lr=0.00197 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[009] loss=0.01449 | val_auc=0.6449 | bestF1=0.6800 | thr*=0.102216 | lr=0.00196 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010] loss=0.01362 | val_auc=0.6401 | bestF1=0.6667 | thr*=0.108426 | lr=0.00195 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[011] loss=0.01388 | val_auc=0.6498 | bestF1=0.6923 | thr*=0.103747 | lr=0.00194 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[012] loss=0.01348 | val_auc=0.6401 | bestF1=0.6923 | thr*=0.102019 | lr=0.00193 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[013] loss=0.01247 | val_auc=0.6353 | bestF1=0.6923 | thr*=0.099348 | lr=0.00192 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[014] loss=0.01175 | val_auc=0.6377 | bestF1=0.6923 | thr*=0.097743 | lr=0.00191 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[015] loss=0.01089 | val_auc=0.6667 | bestF1=0.7059 | thr*=0.096219 | lr=0.00189 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\2742823384.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[016] loss=0.01012 | val_auc=0.6812 | bestF1=0.7200 | thr*=0.090922 | lr=0.00188 | \n",
      "Early stopping.\n",
      "âœ… AE guardado en: C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\comparacion\\dataset_gua_crops\\cropped_images\\splits\\autoencoder_compare | bestF1= 0.7442 thr= 0.128503\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 3 (MEJORADA): AE ENTRENAR + CALIBRAR CON labels.csv ===\n",
    "import os, csv, json, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "from PIL import Image\n",
    "\n",
    "# ----- Config -----\n",
    "SPLITS_DIR = os.path.join(BASE,\"splits\")\n",
    "AE_DIR = os.path.join(SPLITS_DIR, \"autoencoder_compare\"); os.makedirs(AE_DIR, exist_ok=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 256\n",
    "BATCH = 32\n",
    "EPOCHS = 100\n",
    "LR = 2e-3\n",
    "PATIENCE = 10\n",
    "TOPK_RATIO = 0.02  # 2% de pÃ­xeles con mÃ¡s error (mejor para defectos locales)\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ----- Utils -----\n",
    "try:\n",
    "    from pytorch_msssim import ms_ssim\n",
    "    HAS_MSSSIM = True\n",
    "except Exception:\n",
    "    HAS_MSSSIM = False\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, std=0.01): self.std=std\n",
    "    def __call__(self, t):\n",
    "        if self.std<=0: return t\n",
    "        n = torch.randn_like(t)*self.std\n",
    "        t = torch.clamp(t + n, 0.0, 1.0)\n",
    "        return t\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, splits_dir, split, transform=None, only_normals=False):\n",
    "        self.root = os.path.join(splits_dir, split)\n",
    "        self.items = []\n",
    "        with open(os.path.join(self.root, \"labels.csv\"), newline=\"\", encoding=\"utf-8\") as f:\n",
    "            rdr = csv.DictReader(f)\n",
    "            for r in rdr:\n",
    "                rel = r[\"filename\"]; lbl = int(r[\"label\"])\n",
    "                if only_normals and lbl != 0: \n",
    "                    continue\n",
    "                self.items.append((rel, lbl))\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, idx):\n",
    "        rel, lbl = self.items[idx]\n",
    "        p = os.path.join(self.root, rel)\n",
    "        img = Image.open(p).convert(\"RGB\")  # mantenemos 3 canales\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, lbl\n",
    "\n",
    "# ----- Transforms -----\n",
    "tf_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ColorJitter(0.1,0.1,0.1,0.05),\n",
    "    transforms.RandomAffine(degrees=3, translate=(0.02,0.02), scale=(0.98,1.02)),\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(0.01),\n",
    "])\n",
    "tf_eval = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = CSVDataset(SPLITS_DIR, \"train\", transform=tf_train, only_normals=True)\n",
    "val_set   = CSVDataset(SPLITS_DIR, \"val\",   transform=tf_eval,   only_normals=False)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_set,   batch_size=BATCH, shuffle=False, num_workers=0)\n",
    "print(f\"Train imgs (solo normales): {len(train_set)} | Val imgs (mixto): {len(val_set)}\")\n",
    "\n",
    "# ----- Modelo -----\n",
    "class ConvAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 2, 1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32,64, 3, 2, 1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,128,3, 2, 1), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,64, 3,2,1,1), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 32, 3,2,1,1), nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(32, 3,  3,2,1,1), nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x): return self.dec(self.enc(x))\n",
    "\n",
    "def ae_loss(x, xhat):\n",
    "    mse = nn.functional.mse_loss(xhat, x)\n",
    "    if HAS_MSSSIM:\n",
    "        ssim_loss = 1 - ms_ssim(xhat, x, data_range=1.0)\n",
    "        return 0.7*mse + 0.3*ssim_loss\n",
    "    return mse\n",
    "\n",
    "def scores_from_batch(x, xhat, topk_ratio=TOPK_RATIO):\n",
    "    # error por pÃ­xel y Top-K por imagen\n",
    "    err_map = ((x - xhat)**2).mean(1)      # (B,H,W)\n",
    "    flat = err_map.flatten(1)               # (B, H*W)\n",
    "    k = max(1, int(topk_ratio * flat.shape[1]))\n",
    "    vals, _ = torch.topk(flat, k, dim=1)\n",
    "    return vals.mean(1)                     # (B,)\n",
    "\n",
    "model = ConvAE().to(DEVICE)\n",
    "opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS, eta_min=1e-5)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=='cuda'))\n",
    "\n",
    "best_f1, best_thr = 0.0, 0.0\n",
    "bad_epochs = 0\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    # --- train ---\n",
    "    model.train(); run_loss=0.0\n",
    "    for x,_ in train_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
    "            xhat = model(x)\n",
    "            loss = ae_loss(x, xhat)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(opt); scaler.update()\n",
    "        run_loss += loss.item() * x.size(0)\n",
    "    run_loss /= max(1, len(train_loader.dataset))\n",
    "    sched.step()\n",
    "\n",
    "    # --- val: scores + umbral Ã³ptimo por F1 ---\n",
    "    model.eval(); scores=[]; ytrue=[]\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
    "        for x,y in val_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            xhat = model(x)\n",
    "            s = scores_from_batch(x, xhat).detach().cpu().numpy()\n",
    "            scores.extend(s.tolist()); ytrue.extend(list(y.numpy()))\n",
    "    scores = np.array(scores); ytrue = np.array(ytrue)\n",
    "\n",
    "    auc = roc_auc_score(ytrue, scores) if len(np.unique(ytrue))>1 else float(\"nan\")\n",
    "    prec, rec, thr = precision_recall_curve(ytrue, scores)\n",
    "    f1 = (2*prec*rec)/(prec+rec+1e-8)\n",
    "    idx = int(np.argmax(f1))\n",
    "    f1_best = float(f1[idx])\n",
    "    thr_best = float(thr[idx]) if len(thr)>0 else 0.0\n",
    "\n",
    "    improved = f1_best > best_f1\n",
    "    if improved:\n",
    "        best_f1, best_thr = f1_best, thr_best\n",
    "        torch.save(model.state_dict(), os.path.join(AE_DIR, \"ae_best.pt\"))\n",
    "        with open(os.path.join(AE_DIR, \"config.json\"), \"w\") as f:\n",
    "            json.dump({\"threshold\": best_thr, \"topk_ratio\": TOPK_RATIO}, f)\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "\n",
    "    print(f\"[{ep:03d}] loss={run_loss:.5f} | val_auc={auc:.4f} | bestF1={f1_best:.4f} | thr*={thr_best:.6f} \"\n",
    "          f\"| lr={sched.get_last_lr()[0]:.5f} | {'*' if improved else ''}\")\n",
    "\n",
    "    if bad_epochs >= PATIENCE:\n",
    "        print(\"Early stopping.\")\n",
    "        break\n",
    "\n",
    "print(\"âœ… AE guardado en:\", AE_DIR, \"| bestF1=\", round(best_f1,4), \"thr=\", round(best_thr,6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a11ed4",
   "metadata": {},
   "source": [
    "ðŸ”¹ Celda 4 â€” PatchCore (memory bank + umbral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e237ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo parches de TRAIN (normales)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:01<00:00, 61.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco completo: (111616, 384)\n",
      "âœ… Memory bank: (5580, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:06<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL -> ROC-AUC=0.8865 | thr(p95 normals)=0.356087\n",
      "âœ… Umbral guardado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 4: PATCHCORE - BANK + UMBRAL ===\n",
    "import os, json, cv2, numpy as np, torch, torchvision.models as models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "\n",
    "SPLITS_DIR = os.path.join(BASE,\"splits\")\n",
    "PATCH_DIR = os.path.join(BASE,\"patchcore\"); os.makedirs(PATCH_DIR, exist_ok=True)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# extractor\n",
    "backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(DEVICE); backbone.eval()\n",
    "class FeatHook:\n",
    "    def __init__(self, m): self.h=m.register_forward_hook(self.hook); self.feat=None\n",
    "    def hook(self, m, i, o): self.feat=o.detach()\n",
    "    def close(self): self.h.remove()\n",
    "h2 = FeatHook(dict(backbone.named_modules())[\"layer2\"])\n",
    "h3 = FeatHook(dict(backbone.named_modules())[\"layer3\"])\n",
    "\n",
    "def load_img(path, size=IMG_SIZE):\n",
    "    im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    im = cv2.resize(im,(size,size), interpolation=cv2.INTER_AREA)\n",
    "    x = (im.astype(np.float32)/255.0)\n",
    "    x = np.stack([x,x,x],axis=0)\n",
    "    return torch.from_numpy(x).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "def extract_concat_features(pth):\n",
    "    x = load_img(pth)\n",
    "    with torch.no_grad(): _ = backbone(x)\n",
    "    f2, f3 = h2.feat, h3.feat\n",
    "    f3u = torch.nn.functional.interpolate(f3, size=f2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    return torch.cat([f2,f3u], dim=1).squeeze(0)  # (C,H,W)\n",
    "\n",
    "def patchify(F): C,H,W=F.shape; return F.permute(1,2,0).reshape(H*W,C).contiguous()\n",
    "def read_csv(csvp):\n",
    "    rows=[]; \n",
    "    with open(csvp,\"r\",encoding=\"utf-8\") as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            rel,lbl=line.strip().split(\",\"); rows.append((rel,int(lbl)))\n",
    "    return rows\n",
    "\n",
    "# 4.1 memory bank (train solo normales)\n",
    "train_csv = os.path.join(SPLITS_DIR,\"train\",\"labels.csv\")\n",
    "items = read_csv(train_csv)\n",
    "train_imgs = [os.path.join(SPLITS_DIR,\"train\", rel) for rel,lbl in items if lbl==0]\n",
    "\n",
    "patches_all=[]\n",
    "print(\"Extrayendo parches de TRAIN (normales)...\")\n",
    "for p in tqdm(train_imgs):\n",
    "    F = extract_concat_features(p)\n",
    "    P = patchify(F)\n",
    "    P = torch.nn.functional.normalize(P, p=2, dim=1)\n",
    "    patches_all.append(P.cpu().numpy())\n",
    "bank_full = np.vstack(patches_all).astype(np.float32)\n",
    "print(\"Banco completo:\", bank_full.shape)\n",
    "\n",
    "# coreset\n",
    "def random_projection(X, out_dim=128, seed=42):\n",
    "    rng=np.random.default_rng(seed)\n",
    "    R=rng.standard_normal((X.shape[1], out_dim)).astype(np.float32)\n",
    "    Z=X@R; Z/= (np.linalg.norm(Z,axis=1,keepdims=True)+1e-8)\n",
    "    return Z\n",
    "def kcenter_greedy(Z, m, seed=42):\n",
    "    rng=np.random.default_rng(seed); N=Z.shape[0]\n",
    "    start=int(rng.integers(0,N)); centers=[start]\n",
    "    d=np.linalg.norm(Z-Z[start],axis=1)\n",
    "    for _ in range(1,m):\n",
    "        i=int(np.argmax(d)); centers.append(i)\n",
    "        d=np.minimum(d, np.linalg.norm(Z-Z[i],axis=1))\n",
    "    return np.array(centers, dtype=np.int64)\n",
    "\n",
    "CORESET_RATIO = 0.05\n",
    "m = max(1, int(CORESET_RATIO * bank_full.shape[0]))\n",
    "Z = random_projection(bank_full, 128)\n",
    "idx = kcenter_greedy(Z, m)\n",
    "bank = bank_full[idx]\n",
    "np.savez(os.path.join(PATCH_DIR,\"memory_bank_core.npz\"),\n",
    "         bank=bank, img_size=np.array([IMG_SIZE], dtype=np.int32))\n",
    "print(\"âœ… Memory bank:\", bank.shape)\n",
    "\n",
    "# 4.2 calibrar umbral en VAL\n",
    "val_csv = os.path.join(SPLITS_DIR,\"val\",\"labels.csv\")\n",
    "val_items = read_csv(val_csv)\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=3).fit(bank)\n",
    "\n",
    "def anomaly_score(pth):\n",
    "    F = extract_concat_features(pth)\n",
    "    Hf,Wf = F.shape[-2:]\n",
    "    P = patchify(F)\n",
    "    P = torch.nn.functional.normalize(P, p=2, dim=1).cpu().numpy()\n",
    "    dists,_ = knn.kneighbors(P, return_distance=True)\n",
    "    patch_scores = dists.mean(axis=1).reshape(Hf,Wf).astype(np.float32)\n",
    "    return float(patch_scores.max())\n",
    "\n",
    "y_true, s = [], []\n",
    "for rel,lbl in tqdm(val_items):\n",
    "    p = os.path.join(SPLITS_DIR,\"val\", rel)\n",
    "    y_true.append(lbl); s.append(anomaly_score(p))\n",
    "y_true = np.array(y_true); s = np.array(s)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "auc = roc_auc_score(y_true, s)\n",
    "prec,rec,thr = precision_recall_curve(y_true, s)\n",
    "f1 = (2*prec*rec)/(prec+rec+1e-8)\n",
    "thr_p95 = float(np.percentile(s[y_true==0], 95))\n",
    "print(f\"VAL -> ROC-AUC={auc:.4f} | thr(p95 normals)={thr_p95:.6f}\")\n",
    "\n",
    "with open(os.path.join(PATCH_DIR,\"config.json\"),\"w\") as f:\n",
    "    json.dump({\"threshold\": thr_p95}, f)\n",
    "print(\"âœ… Umbral guardado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6fb4f",
   "metadata": {},
   "source": [
    "ðŸ”¹ Celda 5 â€” EvaluaciÃ³n AE en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da8b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\3356156489.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(os.path.join(AE_DIR,\"ae_best.pt\"), map_location=DEVICE))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_20772\\3356156489.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AE / TEST (Top-K) ===\n",
      "ROC-AUC: 0.733\n",
      "Precision: 0.5833 Recall: 0.7778 F1: 0.6667\n",
      "CM [[TN FP],[FN TP]]:\n",
      " [[ 9 15]\n",
      " [ 6 21]]\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 5 (MEJORADA): EVAL AE EN TEST CON labels.csv + Top-K ===\n",
    "import os, csv, json, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "SPLITS_DIR = os.path.join(BASE,\"splits\")\n",
    "AE_DIR = os.path.join(SPLITS_DIR,\"autoencoder_compare\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 256\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, splits_dir, split, transform=None):\n",
    "        self.root = os.path.join(splits_dir, split)\n",
    "        self.items = []\n",
    "        with open(os.path.join(self.root, \"labels.csv\"), newline=\"\", encoding=\"utf-8\") as f:\n",
    "            rdr = csv.DictReader(f)\n",
    "            for r in rdr:\n",
    "                self.items.append((r[\"filename\"], int(r[\"label\"])))\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, idx):\n",
    "        rel, lbl = self.items[idx]\n",
    "        p = os.path.join(self.root, rel)\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, lbl\n",
    "\n",
    "tf = transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)), transforms.ToTensor()])\n",
    "test_set  = CSVDataset(SPLITS_DIR, \"test\", transform=tf)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# misma arquitectura\n",
    "class ConvAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, 3, 2, 1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(32,64, 3, 2, 1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Conv2d(64,128,3, 2, 1), torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.dec = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(128,64, 3,2,1,1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.ConvTranspose2d(64, 32, 3,2,1,1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.ConvTranspose2d(32, 3,  3,2,1,1), torch.nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x): return self.dec(self.enc(x))\n",
    "\n",
    "def scores_from_batch(x, xhat, topk_ratio):\n",
    "    err_map = ((x - xhat)**2).mean(1)      # (B,H,W)\n",
    "    flat = err_map.flatten(1)\n",
    "    k = max(1, int(topk_ratio * flat.shape[1]))\n",
    "    vals, _ = torch.topk(flat, k, dim=1)\n",
    "    return vals.mean(1)\n",
    "\n",
    "# cargar modelo + umbral + topk_ratio\n",
    "ae = ConvAE().to(DEVICE)\n",
    "ae.load_state_dict(torch.load(os.path.join(AE_DIR,\"ae_best.pt\"), map_location=DEVICE))\n",
    "ae.eval()\n",
    "cfg = json.load(open(os.path.join(AE_DIR,\"config.json\")))\n",
    "thr_ae = cfg[\"threshold\"]; topk_ratio = cfg.get(\"topk_ratio\", 0.02)\n",
    "\n",
    "y_true, scores = [], []\n",
    "with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
    "    for x,y in test_loader:\n",
    "        x=x.to(DEVICE)\n",
    "        xhat=ae(x)\n",
    "        s = scores_from_batch(x, xhat, topk_ratio).item()\n",
    "        scores.append(s); y_true.append(int(y.item()))\n",
    "\n",
    "y_true = np.array(y_true); scores=np.array(scores)\n",
    "y_pred = (scores>thr_ae).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_true, scores) if len(np.unique(y_true))>1 else float(\"nan\")\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"=== AE / TEST (Top-K) ===\")\n",
    "print(\"ROC-AUC:\", round(auc,4))\n",
    "print(\"Precision:\", round(prec,4), \"Recall:\", round(rec,4), \"F1:\", round(f1,4))\n",
    "print(\"CM [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7616496",
   "metadata": {},
   "source": [
    "ðŸ”¹ Celda 6 â€” EvaluaciÃ³n PatchCore en test + comparaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e47b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PATCHCORE / TEST ===\n",
      "ROC-AUC: 0.9506\n",
      "Precision: 0.96 Recall: 0.8889 F1: 0.9231\n",
      "CM [[TN FP],[FN TP]]:\n",
      " [[23  1]\n",
      " [ 3 24]]\n",
      "\n",
      "=== COMPARACIÃ“N (TEST) ===\n",
      "Modelo        AUC     Prec    Recall  F1\n",
      "Autoencoder   0.7330  0.5833  0.7778  0.6667\n",
      "PatchCore     0.9506  0.9600  0.8889  0.9231\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 6: EVAL PATCHCORE EN TEST + COMPARACIÃ“N ===\n",
    "import os, json, cv2, numpy as np, torch, torchvision.models as models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "SPLITS_DIR = os.path.join(BASE,\"splits\")\n",
    "PATCH_DIR = os.path.join(BASE,\"patchcore\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# cargar bank + umbral\n",
    "mb = np.load(os.path.join(PATCH_DIR,\"memory_bank_core.npz\"), allow_pickle=True)\n",
    "bank = mb[\"bank\"]\n",
    "thr_pc = json.load(open(os.path.join(PATCH_DIR,\"config.json\")))[\"threshold\"]\n",
    "knn = NearestNeighbors(n_neighbors=3).fit(bank)\n",
    "\n",
    "# extractor\n",
    "backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(DEVICE); backbone.eval()\n",
    "class FeatHook:\n",
    "    def __init__(self,m): self.h=m.register_forward_hook(self.hook); self.feat=None\n",
    "    def hook(self,m,i,o): self.feat=o.detach()\n",
    "    def close(self): self.h.remove()\n",
    "h2=FeatHook(dict(backbone.named_modules())[\"layer2\"])\n",
    "h3=FeatHook(dict(backbone.named_modules())[\"layer3\"])\n",
    "\n",
    "def load_img(path, size=IMG_SIZE):\n",
    "    im=cv2.imread(path, cv2.IMREAD_GRAYSCALE); im=cv2.resize(im,(size,size), interpolation=cv2.INTER_AREA)\n",
    "    x=(im.astype(np.float32)/255.0); x=np.stack([x,x,x],axis=0)\n",
    "    return torch.from_numpy(x).unsqueeze(0).to(DEVICE)\n",
    "def extract_concat_features(pth):\n",
    "    x=load_img(pth)\n",
    "    with torch.no_grad(): _=backbone(x)\n",
    "    f2,f3=h2.feat,h3.feat\n",
    "    f3u=torch.nn.functional.interpolate(f3, size=f2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    return torch.cat([f2,f3u], dim=1).squeeze(0)\n",
    "def patchify(F): C,H,W=F.shape; return F.permute(1,2,0).reshape(H*W,C).contiguous()\n",
    "\n",
    "# leer test labels\n",
    "items=[]\n",
    "with open(os.path.join(SPLITS_DIR,\"test\",\"labels.csv\"),\"r\",encoding=\"utf-8\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        rel,lbl=line.strip().split(\",\"); items.append((rel,int(lbl)))\n",
    "\n",
    "y_true_pc, scores_pc = [], []\n",
    "for rel,lbl in items:\n",
    "    p = os.path.join(SPLITS_DIR,\"test\", rel)\n",
    "    F = extract_concat_features(p)\n",
    "    Hf,Wf = F.shape[-2:]\n",
    "    P = patchify(F)\n",
    "    P = torch.nn.functional.normalize(P, p=2, dim=1).cpu().numpy()\n",
    "    dists,_ = knn.kneighbors(P, return_distance=True)\n",
    "    score = float(dists.mean(axis=1).reshape(Hf,Wf).max())\n",
    "    y_true_pc.append(lbl); scores_pc.append(score)\n",
    "\n",
    "y_true_pc = np.array(y_true_pc); scores_pc=np.array(scores_pc)\n",
    "y_pred_pc = (scores_pc>thr_pc).astype(int)\n",
    "\n",
    "auc_pc = roc_auc_score(y_true_pc, scores_pc)\n",
    "prec_pc, rec_pc, f1_pc, _ = precision_recall_fscore_support(y_true_pc, y_pred_pc, average=\"binary\", zero_division=0)\n",
    "cm_pc = confusion_matrix(y_true_pc, y_pred_pc)\n",
    "\n",
    "print(\"=== PATCHCORE / TEST ===\")\n",
    "print(\"ROC-AUC:\", round(auc_pc,4))\n",
    "print(\"Precision:\", round(prec_pc,4), \"Recall:\", round(rec_pc,4), \"F1:\", round(f1_pc,4))\n",
    "print(\"CM [[TN FP],[FN TP]]:\\n\", cm_pc)\n",
    "\n",
    "# comparaciÃ³n rÃ¡pida\n",
    "def fmt(x): \n",
    "    return \"nan\" if (isinstance(x,float) and (x!=x)) else f\"{x:.4f}\"\n",
    "print(\"\\n=== COMPARACIÃ“N (TEST) ===\")\n",
    "print(f\"{'Modelo':<12}  AUC     Prec    Recall  F1\")\n",
    "print(f\"{'Autoencoder':<12}  {fmt(roc_auc_score(y_true, scores) if len(np.unique(y_true))>1 else float('nan'))}  \"\n",
    "      f\"{fmt(precision_recall_fscore_support(y_true, (scores>thr_ae).astype(int), average='binary', zero_division=0)[0])}  \"\n",
    "      f\"{fmt(precision_recall_fscore_support(y_true, (scores>thr_ae).astype(int), average='binary', zero_division=0)[1])}  \"\n",
    "      f\"{fmt(precision_recall_fscore_support(y_true, (scores>thr_ae).astype(int), average='binary', zero_division=0)[2])}\")\n",
    "print(f\"{'PatchCore':<12}  {fmt(auc_pc)}  {fmt(prec_pc)}  {fmt(rec_pc)}  {fmt(f1_pc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96102944",
   "metadata": {},
   "source": [
    "ðŸ”¹ Celda 7 â€” (Opcional) Visuales PatchCore (overlay/heat/mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9abff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Visuales guardadas en: C:\\Users\\DELL\\Desktop\\UNI-LEON\\DP ULE\\comparacion\\dataset_gua_crops\\cropped_images\\patchcore\\viz\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 7: VISUALIZACIÃ“N PATCHCORE (opcional) ===\n",
    "import cv2, json, numpy as np, os\n",
    "\n",
    "viz_dir = os.path.join(PATCH_DIR, \"viz\"); os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "def score_map(pth):\n",
    "    F = extract_concat_features(pth)\n",
    "    Hf,Wf = F.shape[-2:]\n",
    "    P = patchify(F)\n",
    "    P = torch.nn.functional.normalize(P, p=2, dim=1).cpu().numpy()\n",
    "    dists,_ = knn.kneighbors(P, return_distance=True)\n",
    "    return dists.mean(axis=1).reshape(Hf,Wf).astype(np.float32)\n",
    "\n",
    "def heat_overlay(img_path, patch_scores, percent=98):\n",
    "    raw = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    h = cv2.resize(patch_scores, (raw.shape[1], raw.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "    h_norm = (h - h.min())/(h.max()-h.min()+1e-8)\n",
    "    h_u8 = (h_norm*255).astype(np.uint8)\n",
    "    heat = cv2.applyColorMap(h_u8, cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(cv2.cvtColor(raw, cv2.COLOR_GRAY2BGR), 0.6, heat, 0.4, 0)\n",
    "\n",
    "    t = np.percentile(h_u8, percent)\n",
    "    _, mask = cv2.threshold(h_u8, t, 255, cv2.THRESH_BINARY)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3,3),np.uint8),1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3,3),np.uint8),1)\n",
    "    cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) < 25: continue\n",
    "        cv2.polylines(overlay, [c], True, (0,255,0), 2)\n",
    "    return overlay, heat, mask\n",
    "\n",
    "# genera 8 visuales\n",
    "items = []\n",
    "with open(os.path.join(SPLITS_DIR,\"test\",\"labels.csv\"),\"r\",encoding=\"utf-8\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        rel,lbl=line.strip().split(\",\"); items.append((rel,int(lbl)))\n",
    "for rel,_ in items[:8]:\n",
    "    p = os.path.join(SPLITS_DIR,\"test\", rel)\n",
    "    sm = score_map(p)\n",
    "    ov, heat, mask = heat_overlay(p, sm, percent=98)\n",
    "    base = os.path.splitext(os.path.basename(p))[0]\n",
    "    cv2.imwrite(os.path.join(viz_dir, f\"{base}_overlay.png\"), ov)\n",
    "    cv2.imwrite(os.path.join(viz_dir, f\"{base}_heat.png\"), heat)\n",
    "    cv2.imwrite(os.path.join(viz_dir, f\"{base}_mask.png\"), mask)\n",
    "\n",
    "print(\"âœ… Visuales guardadas en:\", viz_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
